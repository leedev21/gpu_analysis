import re
import json
import os
import datetime
from theory.run import run_op, op_efficiency, ReportGenerator, format_data
from omegaconf.listconfig import ListConfig
from omegaconf.dictconfig import DictConfig
from omegaconf import OmegaConf
from collections import OrderedDict, defaultdict
from typing import Optional, Dict, List, Tuple
from copy import deepcopy


class Report(object):
    def __init__(self):
        self.op_log_files = {}
        self.generators = {}
        self.last_reported_index = -1
        self.data = []
        self.theory_latency = []

    def __call__(self, test_case, _mean, _min, _max, acc):
        self.data.append((test_case, _mean, _min, _max, acc))

    def add_target(self, target):
        self.target = target

    def config(self, attr, value):
        if hasattr(self, attr):
            setattr(self, attr, value)
        else:
            self.conf[attr] = value

    def get_shape(self, test_case):
        _in = []
        if hasattr(test_case, 'input'):
            for tensor in test_case.input:
                if isinstance(tensor, ListConfig):
                    _in.append(list(tensor))
                elif isinstance(tensor, DictConfig):
                    if '_tensor' in tensor:
                        _in.append(list(tensor['_tensor']))
                # Skip scalar parameters like epsilon, they are not tensors
                # and should not be included in shape information
        return _in

    def check_limit(self, test_case, config, limit):
        shape = self.get_shape(test_case)
        if shape:
            theory_latency = run_op(config['hw'], test_case.name, shape)
            if limit and theory_latency['latency'] >= limit:
                print('limit:', limit, '; theory:', theory_latency['latency'])
                return True
            self.theory_latency.append(theory_latency)
        return False

    def report(self, args, config):
        print('='*50, 'Report', '='*50)
        print(args)

        op_data = {}
        for i, line in enumerate(self.data):
            test_case, _mean, _min, _max, acc = line
            shape = self.get_shape(test_case)
            efficient = 0
            theory_latency = 0
            # try:
            efficient = op_efficiency(config['hw'], test_case.name, shape, _min)
            theory_latency = self.theory_latency[i]
            # except:
            #     pass
            _mean = round(_mean, 2)
            _min = round(_min, 2)
            _max = round(_max, 2)
            print(test_case, _mean, _min, _max, theory_latency['latency'], efficient['flops_utilization'], efficient['io_utilization'])

            op_name = self.extract_operation_name(test_case)
            print("test_case", test_case)
            processed_data = {
                'test_case': test_case,
                'mean': _mean,
                'min': _min,
                'max': _max,
                'efficient': efficient,
                'theory_latency': theory_latency,
                'shape': shape
            }

            # æ£€æŸ¥é”®æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆå§‹åŒ–ä¸ºç©ºåˆ—è¡¨
            if op_name not in op_data:
                op_data[op_name] = []
            op_data[op_name].append(processed_data)
        hw_name = config.get('hw', 'Unknown')
        timestamp = datetime.datetime.now().strftime("%Y-%m-%d_%H-%M-%S")

        # Create a separate log file for each operation
        log_files = {}
        for op_name, data in op_data.items():
            log_path = self.save_log_file(op_name, hw_name, timestamp, data, args, config)
            log_files[op_name] = log_path

        return log_files

    def instant_report(self, args, config):
        if not hasattr(self, 'last_reported_index'):
            self.last_reported_index = -1
            self.op_log_files = {}
            self.first_file_created = {}

        if len(self.data) <= self.last_reported_index + 1:
            return None

        i = self.last_reported_index + 1
        test_case, _mean, _min, _max, acc = self.data[i]
        shape = self.get_shape(test_case)
        hw_name = config.get('hw', 'Unknown')
        if not hasattr(test_case, 'name'):
            return
        efficient = None
        theory_latency = None
        if not acc:
            try:
                efficient = op_efficiency(hw_name, test_case.name, shape, _min)
                theory_latency = self.theory_latency[i] if i < len(self.theory_latency) else None
                # print("efficient",efficient)
                # print("theory_latency",theory_latency)
            except Exception as e:
                print(f"Error calculating efficiency: {e}")

            # ç”Ÿæˆæ ¼å¼åŒ–æ•°æ®
        raw_datas = data_gather(args, config, self.data[i], efficient, theory_latency)

        op_name = raw_datas[0]['config']['op_name']
        # å…³é”®é€»è¾‘ï¼šç”Ÿæˆæˆ–å¤ç”¨æ–‡ä»¶è·¯å¾„
        if op_name not in self.op_log_files:
            # é¦–æ¬¡ç”Ÿæˆæ—¶é—´æˆ³å’Œæ–‡ä»¶å
            timestamp = datetime.datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
            model_report = f"{args.training.report}/{hw_name}_{op_name}_{timestamp}.log"
            self.op_log_files[op_name] = model_report
            print(f"ğŸ“ æ–°æ—¥å¿—æ–‡ä»¶å·²åˆ›å»ºï¼š{model_report}")  # æ–°å¢æç¤º
        else:
            # å¤ç”¨å·²æœ‰æ–‡ä»¶è·¯å¾„
            model_report = self.op_log_files[op_name]
            print(f"ğŸ“‚ å¤ç”¨å·²æœ‰æ—¥å¿—æ–‡ä»¶ï¼š{model_report}")  # æ–°å¢æç¤º
         # è·å–æˆ–åˆ›å»ºç”Ÿæˆå™¨

        name = f"{hw_name}_{op_name.replace('::', '-')}"
        if op_name not in self.generators:
            self.generators[op_name] = ReportGenerator(name=name)
        generator = self.generators[op_name]

        # è¦†ç›–å†™å…¥æ–‡ä»¶
        for raw_data in raw_datas:
            formatted_data = format_data(raw_data)
            generator.DataFrame(formatted_data)
        generator.reindex(columns=format_data._columns)
        generator.to_report(model_report, index=False)

        # æ›´æ–°ç´¢å¼•
        self.last_reported_index = i
        return model_report

def data_gather(args, config, test_case_data, efficient, theory):
    """Extract and structure raw performance test data dynamically.

    Args:
        args: Command line arguments dict (any structure)
        hw: Hardware name string
        test_case_data: Tuple of (test_case_dict, mean_time, min_time, max_time)
        efficient: Efficiency metrics dict (any structure)
        theory: Theoretical latency dict (any structure)

    Returns:
        Dictionary containing all input data in structured form, preserving
        original nested structures while adding some standard fields.
    """
    test_case, _mean, _min, _max, acc = test_case_data
    op_name = test_case.get('name', 'unknown').replace('::', '-')
    hw = config.get('hw', 'Unknown')
    # Create structured raw data with flat organization
    data = []
    result = {
        'config': {
            'hardware': hw,
            'precision': 'unknown',
            'op_name': op_name
        },
        'test_case': {
            'name': test_case.get('name'),
            **{k: v for k, v in test_case.items() if k != 'name'}
        },
        'raw_args': args
    }

    def process_efficient_metrics(efficient):
        """è‡ªé€‚åº”å¤„ç†åµŒå¥—çš„æ€§èƒ½æŒ‡æ ‡ï¼ˆè·³è¿‡shapeå­—æ®µï¼‰"""
        processed = efficient.copy()

        # éœ€è¦è·³è¿‡çš„å­—æ®µåˆ—è¡¨
        skip_keys = {'shape', 'in', 'out', 'flops_fwd_bwd', '2D_flops', 'activation', 'params'  }  # æ·»åŠ éœ€è¦è·³è¿‡çš„å­—æ®µ

        for metric_key in list(processed.keys()):
            # è·³è¿‡å½¢çŠ¶ç›¸å…³å­—æ®µ
            if metric_key in skip_keys:
                processed.pop(metric_key)
                continue

            # å¤„ç†å­—å…¸ç±»å‹çš„æŒ‡æ ‡
            if isinstance(processed[metric_key], dict):
                metric_data = processed.pop(metric_key)

                for dim, values in metric_data.items():
                    new_key = f"{metric_key}_{dim}"

                    # è·³è¿‡éæ•°å€¼å­—æ®µ
                    if dim in skip_keys or not isinstance(values, (int, float, list)):
                        processed[new_key] = values
                        continue

                    # å¯¹æ•°å€¼åˆ—è¡¨æ±‚å’Œï¼Œæ ‡é‡ç›´æ¥å­˜å‚¨
                    if isinstance(values, list):
                        processed[new_key] = sum(values)
                    else:
                        processed[new_key] = values

        return processed

    def process_test_case(test_case):
        """å¤„ç†æµ‹è¯•ç”¨ä¾‹æ•°æ®ï¼Œè¿”å›æ‰å¹³åŒ–çš„å­—å…¸"""
        def flatten_omega_config(d, parent_key='', sep='_'):
            items = []
            for k, v in d.items():
                new_key = f"{parent_key}{sep}{k}" if parent_key else k
                if isinstance(v, (dict, DictConfig)):
                    items.extend(flatten_omega_config(v, new_key, sep=sep).items())
                else:
                    items.append((new_key, v))
            return dict(items)

        test_case_dict = OmegaConf.to_container(test_case, resolve=True)

        # å¤„ç† input å­—æ®µ
        if 'input' in test_case_dict:
            input_list = test_case_dict['input']
            shape_params = []
            operation_params = {}

            # åˆ†ç¦»å½¢çŠ¶å‚æ•°å’Œæ“ä½œå‚æ•°
            for item in input_list:
                if isinstance(item, (list, ListConfig)):
                    shape_params.append(list(item))
                elif isinstance(item, (dict, DictConfig)):
                    flat_dict = flatten_omega_config(item)
                    for key, value in flat_dict.items():
                        # ç”Ÿæˆå”¯ä¸€é”®åï¼ˆè‡ªåŠ¨æ·»åŠ åç¼€ï¼‰
                        new_key = key
                        suffix = 1
                        while new_key in operation_params:
                            new_key = f"{key}_{suffix}"
                            suffix += 1
                        operation_params[new_key] = value

            # ç”Ÿæˆ input_shape
            if shape_params:
                test_case_dict["input_shape"] = (
                    str(shape_params[0])
                    if len(shape_params) == 1
                    else str(shape_params)
                )

            # åˆå¹¶æ“ä½œå‚æ•°åˆ°é¡¶å±‚ï¼ˆä¸è¦†ç›–å·²æœ‰å­—æ®µï¼‰
            for key, value in operation_params.items():
                if key not in test_case_dict:
                    test_case_dict[key] = value

            # ç§»é™¤åŸå§‹ input å­—æ®µ
            del test_case_dict['input']

        return test_case_dict

    process_test_case_dict = process_test_case(test_case)
    precision = process_test_case_dict['precision'] if 'precision' in process_test_case_dict else args.training.precision
    if 'precision' in process_test_case_dict :
        del process_test_case_dict['precision']
    if 'name' in process_test_case_dict:
        del process_test_case_dict['name']
    result['kwargs'] = process_test_case_dict

    result["config"]['dtype'] = precision
    if 'hardware' in result['config']:
        del result['config']['hardware']
    del result['config']['precision']

    if acc:
        for line in acc:
            data.append(deepcopy(result))
            data[-1]["acc"] = {}
            for i, value in enumerate(line):
                data[-1]["acc"][config['format'][i]] = value
    else:
        result["duration"] = {
            'mean': _mean,
            'min': _min,
            'max': _max
        }
        # Process theory latency
        if theory:
            result['theory'] = {
                'latency': theory.get('latency', None)
            }
        if efficient:
            result['efficient'] = process_efficient_metrics(efficient)
        data = [result]

    return data


report = Report()
