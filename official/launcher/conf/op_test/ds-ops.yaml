- name: vllm.ops._C::linear_quant
  size:
    BS: [128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768]
    ID: [6144, 8192, 13824, 16384]
    OD: [48, 56, 64, 108, 128]
  input:
  - out:
      _tensor: [BS, OD]
    lhs:
      _tensor: [BS, ID]
    rhs:
      _tensor: [OD, ID] # -127, 127 torch.int8
    bias:
      _tensor: [OD]
    lhs_scale:
      _tensor: [1]
    rhs_scale:
      _tensor: [OD]
  output: [out]
  _name: atenLinearQuant
- name: vllm.ops._C::rms_norm
  size:
    batch_size: [1, 2, 4, 8, 16, 24, 32]
    seq_len: [4, 8, 16]
    hidden_size: [512]
  input:
  - output:
      _tensor: [batch_size, seq_len, hidden_size]
    input:
      _tensor: [batch_size, seq_len, hidden_size]
    weight:
      _tensor: [hidden_size]
    epsilon: 1.0e-06
  output: [output]
  _name: vllmRmsNorm