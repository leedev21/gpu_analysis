layer:
  name: quant_activation
  type:
    - Torch
    - Vllm
  seq_length:
    - 4096
  shape: 
    - ['seq_length', 12288]
  init: 
    - [12288, 6144, False]
  micro_batch_size: 1
  precision: bf16