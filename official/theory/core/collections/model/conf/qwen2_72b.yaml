model:
  name: qwen2_72b
  size: 72
  num_layers: 80
  hidden_size: 8192
  ffn_hidden_size: 24576
  num_attention_heads: 64
  num_hidden_dim: 128
  num_query_groups: 8
  vocab_size: 152064
  swiglu: true
  normalization: rmsnorm
  position_embedding_type: rope
  attention_type: multihead