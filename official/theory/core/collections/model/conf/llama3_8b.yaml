model:
  name: LLama3_8B
  size: 8
  num_layers: 32
  hidden_size: 4096
  ffn_hidden_size: 6144
  num_attention_heads: 32
  kv_channels: null
  num_query_groups: 8
  swiglu: true
  vocab_size: 128257